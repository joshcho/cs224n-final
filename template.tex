\documentclass{article}

\usepackage[final]{neurips_2019}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage{verbatim}
\usepackage{xcolor}
\usepackage{lipsum}

\newcommand{\note}[1]{\textcolor{blue}{{#1}}}

\title{
  IAKG: Importance-augmented Knowledge Graphs \\
  \vspace{1em}
  \small{\normalfont Stanford CS224N Custom Project}  % Select one and delete the other
}

\author{
  Josh Cho \\
  Department of Computer Science \\
  Stanford University \\
  \texttt{joshcho@stanford.edu} \\
  % Examples of more authors
  % \And
  % Name \\
  % Department of Computer Science \\
  % Stanford University \\
  % \texttt{name@stanford.edu} \\
  % \And
  % Name \\
  % Department of Computer Science \\
  % Stanford University \\
  % \texttt{name@stanford.edu}
}

\begin{document}

\maketitle

\begin{abstract}
  In recent years, Pre-trained Language Models (PLMs) have seen a meteoric rise, largely because through their training process, PLMs form a rich, implicit representation of domain knowledge. Yet its implicit nature makes knowledge inscrutable, which calls the need for explicit representations like Knowledge Graphs (KGs). KGs, while powerful in representing complex relationships between entities, do not capture priority between triples. In this paper, we propose a method for augmenting KGs with importance weights using Wikipedia as proxy for importance. As Wikipedia is limited as a dataset, we use PLMs to generalize the notion of importance from the Wikipedia dataset. We see importance-augmented knowledge graph as an important step in constructing richer explicit representations of knowledge.
\end{abstract}

\section{Background}
Knowledge graphs (KGs) are a popular and effective way to represent structured knowledge. They are composed of entities (nodes) and relationships (edges) between those entities. KGs have been used in various tasks such as question answering, recommendation systems, and information retrieval.

\subsection{Limitations of Knowledge Graphs}
Formally a knowledge graph $\mathcal{KG}$ can be defined as:
\begin{equation*}
  \mathcal{KG} = \{\mathcal{E}, \mathcal{R}, \mathcal{T}\}
\end{equation*}
where $\mathcal{E}$ is the set of entities (e.g. $\text{Einstein}, \text{Germany}, \text{Theory of Relativity}$) and $\mathcal{R}$ is the set of relations (e.g. $\text{born in}, \text{discovered}$). $\mathcal{T}$ is the set of triples in the form of $(h,r,t)$ with $h$ as head, $t$ as tail, and $r$ as relation, where $h,t \in \mathcal{E}$ and $r \in \mathcal{R}$. Thus for the fact ``Einstein is born in Germany'', $h = \text{Einstein}$, $r = \text{born}$, and $t = \text{Germany}$.

If a knowledge graph is to be a proxy for how knowledge rests in the mind, then a knowledge graph --- specifically a knowledge graph triple --- is insufficient at representing factoids in the mind. Consider the example above with Einstein. The two facts ``Einstein is born in Germany'' and ``Einstein discovered theory of relativity'' are represented as triples in the knowledge graph. Yet consider that to a human mind, Einstein's discovery of theory of relativity is more ``important'' than his birthplace. Knowledge graph representation fails to capture the priority between these two factoids with which most humans would agree.

An immediate counterpoint is the subjectivity of ``importance''. To some minds (perhaps a student studying the nationality of prominent scientists), Einstein's birthplace might be of greater importance than his discovery. Yet the subjective nature of the object of study should not completely discourage the study of it; rather, the difficulty should invite better methods to capture that information.

Besides, to the authors a knowledge graph as it stands is limited, and some notion of weights in relationships must exist in order to better represent knowledge itself.

\subsection{Importance-augmented Knowledge Graph}
Formally a weighted knowledge graph can be defined as:
\begin{equation*}
  \mathcal{WKG} = \{\mathcal{E}, \mathcal{R}, \mathcal{T}, f_w\}
\end{equation*}
where $\mathcal{E}, \mathcal{R}$ and $\mathcal{T}$ remain as in $\mathcal{KG}$, and $f_w : \mathcal{T} \to [0,1]$ is a function from KG triple to the associated weight.

A general method for incorporating weights for link prediction has been studied[CITE], yet most weights are confidence scores, i.e. measuring the uncertainty of the triple. We see confidence scores as helpful but ultimately uninteresting. Importance as weights are interesting but, as mentioned, perhaps difficult to study due to its subjective nature.

\subsection{KG-BERT}
In recent years, we have witnessed a meteoric rise of pre-trained language models (PLMs) like BERT. Trained on a very large corpus, PLMs have demonstrated ability to answer questions that require domain knowledge, leading many to hypothesize PLMs to have implicit representation of knowledge. Contrast this with knowledge graphs: PLM is a rich, implicit representation of knowledge whereas KG is a structured, explicit representation of knowledge.

Several attempts have been made to combine the advantages of these two representations. Most notable attempt is KG-BERT, which performs several KG-specific tasks like link prediction, relation prediction, and triple classification using PLMs. Key idea is to convert knowledge graph triples into sequence of tokens, using the sequence as input tto the BERT model. KG-BERT has seen reasonable success, with some improvements made in PKGC.

\subsection{Importance in LLMs}
In the previous section we mentioned how PLM has a rich representation of knowledge. What is meant by a ``rich'' representation of knowledge? Let us consider a conversation with GPT-4, a recent LLM, shown in Figure \ref{img1}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{einstein_gpt4.png}
  \caption{Conversation with GPT-4 on Ordering Einstein Facts based on Importance}
  \label{img1}
\end{figure}

We see in the conversation that GPT-4 attempts to order facts about Einstein based on importance. It also notes Einstein's discovery is more important than his birthplace. We can empirically note that GPT-4 can ``weight'' different relationships based on a notion of importance, whereas KGs are structurally incapable of such task. Thus it is plausible that if we want to create importance-augmented knowledge graphs, we can extract implicit knowledge in them for importance in triples.

While no systematic inquiry has been made as to whether LLMs possess a robust implicit representation of importance of facts, we hypothesize that the success of LLMs imply a rich implicit representation, which serves as the motivation for our experiments.

\subsection{Contributions}

Therefore, we'd like to leverage PLMs in order to augment KGs with importance. In order to use PLMs, we must fine-tune it to our needs; unfortunately, there exist no publicly available knowledge graph datasets that label edges with importance. Thus we use Wikipedia articles as proxy for importance in a triple: specifically, given triple $(h,r,t)$, position of $t$ in the Wikipedia article of $h$ is used to approximate $f_w(h,r,t)$. Then a BERT model is fine-tuned on this data in order to approximate a general $f_w$ function.

In this paper, we present a model that is capable of computing importance scores using Wikipedia as proxy for importance. This model is then used to augment an existing KG with several important scores for completeness.

\section{Importance Score Extraction from Wikipedia}

In this section, we will discuss the process of preprocessing Wikipedia articles and the method used to compute importance scores for the generated triples.

\subsection{Motivation}

Given a triple $(h,r,t)$, we wanted a dataset that gives us $w_{h,r,t}$ where $w_{h,r,t} = f_w(h,r,t)$. Yet as mentioned above, there are no publicly available datasets, so we have to generate $w_{h,r,t}$. Three sources that implicitly capture these relationships came to mind: LLMs, Google, and Wikipedia.

\subsubsection{LLMs as Source}
As demonstrated above with GPT-4, with proper prompting, we can extract information about importance of facts from LLMs. We however moved away from this approach for several reasons:

\begin{enumerate}
\item We prefer human-generated data as the baseline for training our model.
\item Using data generated by LLM to fine-tune BERT seems unwise, and may exacerbate the biases.
\item LLMs are computationally expensive to run inference, and this is an issue when there are triples on the order of a million. A simple backhand calculation: if we generate 1 token per second and each triple has 10 tokens on average, then generating data for 1M triples takes 10M seconds, which is near 4 months.
\end{enumerate}

\subsubsection{Google as Source}
Let $T_{h,r,t}$ be the textual representation of triple $(h,r,t)$ e.g.
\begin{equation*}
  T_{\text{Albert\_Einstein}, \text{wasBornIn}, \text{Germany}} = \text{"Albert Einstein was born in Germany"}
\end{equation*}

Then the number of Google search results of $T_{h,r,t}$ can be used to compute $w_{h,r,t}$, with appropriate normalization. We see this approach as interesting, albeit with high variance and noise. We suggest the number of Google search results be used as a supplementary feature in future work.

\subsubsection{Wikipedia as Source}
When using Wikipedia as a source, we assume that earlier a fact shows in a Wikipedia article, more important the fact is. We see this assumption as being largely true, as Wikipedia articles are edited by humans with implicit goal of presenting relevant information. The assumption fails sometimes when, for instance, basic information (like birthplace) about a person is presented earlier than more critical information.

Given a triple, we use the index of tail in the Wikipedia article of head in order to compute the importance score. There are different ways to index the tail, which we will go over in subsequent sections.

\subsection{Dataset}

We used YAGO3-10 (Yet Another Great Ontology 3-10) as the dataset. YAGO3-10 has 123,182 entities, 37 relations, and 1,179,040 triples (of which 1,079,040 we use for training). All entities are identifiers for Wikipedia articles. In order to remove variance in character count, we default to English Wikipedia. Because of this limitation and other issues like website access and inability to find the entity in a Wikipedia article, we could not use near 69.39\% of the data for training. Ultimately we have 330,248 triples, or 30.61\% of the original dataset for training.

\subsection{Preprocessing Wikipedia Articles}

Given triple $(h,r,t)$, let
\begin{enumerate}
\item $I_{h,t}$ be the link index of entity $t$ in the Wikipedia article of $h$. Link index here is the index of the entity in the ordered list of all entities in the article, in the order that they appear. We use the term link since named entities in Wikipedia articles link to the corresponding Wikipedia article.
\item $I'_{h,t}$ be the link index of entity $t$ in the Wikipedia article of $h$, where infobox is ignored. Example of Infobox is shown in Figure \ref{img2}. Considering links in infobox can be a double-edged sword as sometimes useful entities are in infobox and not in the main article, but also infobox has a regular ordering that does not prioritize importance of facts.
\item $C_{h,t}$ be the character index of the first character of entity $t$ in the Wikipedia article of $h$. Character index here is the number of characters in the article before the first character of entity.
\end{enumerate}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.3\textwidth]{einstein_infobox.png}
  \caption{Wikipedia Infobox on Albert Einstein}
  \label{img2}
\end{figure}

We first extract the position of the tail entity within the Wikipedia article as a proxy.

Although this method has the disadvantage of not indicating the relation type, in most cases, there is one relation type between the head and tail entities. Therefore, the position of the tail entity is sufficient to determine the position of the "triple".

We employ a power decay function for computing the importance scores:

\begin{equation}
      I(x) = \alpha^x
\end{equation}

where $I(x)$ is the importance score, $x$ is the position of the tail entity in the article, and $\alpha$ is a positive constant. The power decay function is chosen because it assigns higher importance to entities mentioned earlier in the article while still considering entities that appear later. This function reflects the intuition that earlier-mentioned entities are generally more important, but it allows for the possibility that later-mentioned entities can still be relevant.

We consider the scenario of preprocessing a Wikipedia article on BERT and computing the positions and importance scores for the triples. This will illustrate the considerations to make when choosing an importance function. We will parse the HTML content and extract the links with appropriate Wikipedia \textit{href} attributes. Table \ref{table:1} shows the triples, their positions, and the importance scores calculated using the power decay function using $\alpha = 0.99$.

\begin{table}[h]
  \label{table:1}
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    Triple & Position & Importance Score \\
    \hline
    (BERT, language\_model, Language model) & 1 & $0.99^{1} \approx 0.99$ \\
    (BERT, publisher, Google) & 2 & $0.99^{2} \approx 0.9801$ \\
    (BERT, related\_work, BookCorpus) & 6 & $0.99^{6} \approx 0.9412$ \\
    (BERT, related\_work, English Wikipedia) & 7 & $0.99^{7} \approx 0.9321$ \\
    (BERT, based\_on, Transformer) & 9 & $0.99^{9} \approx 0.9135$ \\
    \hline
  \end{tabular}

  \caption{Positions and Importance Scores for Triples in the BERT Article}
\end{table}

Upon examining the example, we notice that the importance scores may not accurately reflect the significance of certain entities. For instance, the fact that BERT was trained on BookCorpus and English Wikipedia might be considered less important than the fact that BERT is based on the Transformer architecture. This observation suggests that the structure of Wikipedia articles may affect the computed importance scores, as entities mentioned towards the end of a section could be less important than entities mentioned at the beginning of the next section.

To address this issue, we could modify the importance scoring method to assign higher importance to entities appearing earlier within a section. One possible approach is to combine the power decay function with an additional weighting factor that takes into account the section's position in the article. This way, we can better capture the significance of entities and their relative importance within each section.

An alternative approach for determining importance scores would have been to search for raw text within the article. This method has its own set of advantages, such as being able to identify entities that might not be linked or entities that have different display text. However, this approach can be computationally more expensive, and it may not account for the variability in display text used for the same entity.

Another approach we could consider is to use the character position of the tail entity in the article rather than its position in the ordered list of links. This method would potentially provide a finer-grained measure of the entity's importance by taking into account its exact position in the text. However, it might be more susceptible to the influence of article structure and layout, which could introduce additional noise in the importance scores.

\section{Suggested Future Work}
\subsection{Google as Source}
As mentioned above, we suggest using Google as an alternative way to enrichen a knowledge graph. Once controlled for its variance and erraticity, we believe this can be a useful feature to add to a knowledge graph.

\subsection{Application to KG-BERT}
Initially we sought to use the new representation in order to aid training KG-BERT. We hypothesize that a richer representation of knowledge graphs can help with tasks like link prediction. The computational complexity of these models, however, is very high (\href{https://github.com/yao8839836/kg-bert/issues/8}{taking weeks, up to a month on V100}), which is infeasible given allotted time and resources.

\bibliographystyle{unsrt}
\bibliography{references}

\end{document}